---
title: "Operating System History"
date: 2025-11-20 15:00:00 +0800
categories: [CS basics, Linux] # [Top_category, sub_category]
tags: [os]      # TAG names should always be lowercase
# author:gaoshan
# add image: ![img-description](/assets/img/os.jpg)
---
如果你生活在 20 世纪 40 年代，想“写个程序跑一跑”，画面大概是这样的：你先在桌子前把程序写成一叠打孔卡片，抱着它们走进一个机房，那里站着一台占满整间屋子的怪物。你把卡片交给操作员，然后就只能回去等。等机器轮到你的程序，等它吱呀运转，等打印机吐出一沓结果纸。程序跑完，机器停下，轮到下一位。这台价值连城的计算机，一次只能老老实实地跑一个程序，人则像快递员一样在办公室和机房之间来回奔波。

在早期计算机还很慢的时候，这种高度人工的流程还能勉强接受：像 ENIAC、哈佛 Mark I 这样的机器，跑一个大程序，动辄就是几小时、几天，甚至几周。人类慢一点，不算什么问题。然而，晶体管、大规模集成电路出现后，计算机性能开始以指数级提速。到 50 年代末、60 年代初，尴尬的局面出现了：**机器快得要命，人却慢得要死**——程序真正运行只需要几秒，反而是“排队、装卡、送纸”这些人肉操作耗掉了大部分时间。

工程师们很快意识到：这玩意儿太贵了，总不能让它无所事事地等人。于是，一个关键的想法冒出来：**让计算机“自己管理自己”**——这就是操作系统诞生的历史背景。

---

操作系统（Operating System，OS）本质上也是一个程序，但它和普通程序不一样，它在硬件上拥有最高权限。通常，计算机开机后，第一个被加载的就是操作系统；之后你运行的所有程序——浏览器、游戏、编辑器——都是在操作系统的统筹之下被启动和管理的。

在 20 世纪 50 年代，随着像 IBM 701、IBM 7090 这样的机器逐渐进入大学和研究机构，人们开始为这些大型机编写专门的软件，让“装载程序”这件枯燥重复的事自动化一点。最早的操作系统其实很朴素：它们做的，就是帮你把一堆打孔卡里的程序排好队，一个接一个送进机器里跑。

这就引出了一个关键概念：**批处理（batch processing）**。与其每次只接收一个程序，人工等它跑完再换一个，不如一次性接收一整“批”程序，把它们排成队：程序 A 跑完，立刻接上程序 B，再跑完接着是 C，整个过程由操作系统自动掌控。早期 IBM System/360 上的 OS/360 就是这一类的经典代表，它让大型机从“坐着等人喂活”变成“自己主动找活干”。

---

随着计算机在全球铺开，问题也越来越复杂。原先是“一机一款”时代：在 ENIAC 那样的机器上，程序员只需要针对那台特定硬件写程序即可——处理器、读卡机、打印机都长在一起，不用操心别的型号。到了 60 年代，不同厂家、不同型号的机器大规模出现：同样是 IBM 的大型机，处理器指令集可能类似，但配套的磁带机、打印机、读卡器却千差万别。

这对程序员来说是噩梦。写一个程序本来只要管好业务逻辑，结果还得顺带变成半个硬件工程师：不同打印机的寄存器地址不同、控制命令不同、响应时序不同，每换一台设备就得重写一段底层代码。而且很多设备贵得离谱，程序员根本没机会真正摸到，只能对着说明书写代码，然后祈祷它在客户机房里“不要炸”。

那时候根本没有“即插即用”，只有“插上再祈祷”。

为了解决这一混乱局面，操作系统站出来当“翻译”。它在上层程序和底层硬件之间再加一层抽象：**设备驱动程序（device driver）**。从此，应用程序不再直接和某一型号的打印机对话，而是通过操作系统提供的统一接口，例如调用一个类似于 `print(highscore)` 的函数。至于这条打印指令到底是通过串口发几条控制命令，还是往某个寄存器里写一串奇怪的数，程序员不必操心——那是驱动的工作。

正是这种抽象，让后来各种各样的外设——键盘、鼠标、硬盘、U 盘、摄像头——得以接入系统，而不用每个应用程序都重写一遍支持逻辑。

---

到了 50 年代末，另一件事也变得刺眼：**CPU 太快，机械设备太慢**。打印机、打孔卡读卡器、磁带机这些“铁家伙”，跟电子电路相比简直像蜗牛。程序一旦发出“读磁带”或“打印”的指令，就得等那些咔哒咔哒的机械动作慢慢完成。在这期间，那颗价值堪比一栋楼的处理器只能干瞪眼，浪费时间。

英国曼彻斯特大学在 50 年代末着手设计超级计算机 **Atlas** 时就遇到了这个问题。Atlas 是当时世界上最先进的机器之一，研究团队非常清楚：如果像旧机器一样“一次跑一个程序”，那简直是在烧钱。他们想要的是：**最大限度榨干 CPU 的每一拍时钟**。

于是，一个划时代的系统出现了：**Atlas Supervisor**，可以看作现代操作系统祖师爷之一。

设想一下，当时有人在 Atlas 上跑一个小游戏，要把变量 `highscore` 打到纸上炫耀自己的高分。对打印机来说，这就是慢吞吞地一行行敲字；对 CPU 来说，这可以浪费掉上千、上万次时钟周期。Atlas Supervisor 的做法是：当程序发出打印请求，操作系统立刻把这个程序标记为“正在等待 I/O”，先让它“睡一会儿”，而不是让 CPU 站在旁边干等。

接着，Supervisor 会挑选另一个已经准备好的程序，比如一个正在做矩阵运算的科学计算任务，调度它占用 CPU 继续运行。等打印机终于把 highscore 打完，它会通过中断告诉系统“我好了”。Atlas Supervisor 再把原来的小游戏标记为“就绪”，待下次轮到它时，继续运行 `print` 后面的那行代码。

通过这种调度方式，Atlas 可以实现在同一颗 CPU 上：

* 程序 1 正在算数；
* 程序 2 正在打印；
* 程序 3 正在通过纸带读入数据；

真正做到了早期的**多任务（multitasking）**。Atlas 工程师为了把这个想法发挥到极致，还给机器装了 4 个纸带阅读器、4 个打孔机、最多 8 台磁带机，让大量程序都能同时排队、等待各自的 I/O 设备。

---

不过，让多任务真的“靠谱”运行，还有一个致命难题：**内存**。

每个程序都需要一块内存来放代码和数据。假如机器有 10,000 个内存地址，最简单的做法是：程序 A 占 0–999，程序 B 占 1000–1999，程序 C 占 2000–2999……这样一眼就能看出来谁在哪块。但现实没有这么整齐：程序可能随时需要更多内存，有些程序退出后又把内存腾出来，结果就是：内存被切得支离破碎。

于是，你会看到类似：

* 程序 A 占 0–999 和 3000–3999；
* 程序 B 占 1000–1999；
* 程序 C 占 2000–2499 和 4000–4499；

从系统角度看，这样可以比较充分利用内存碎片；但从程序员角度看，这简直要疯：写个循环去扫一串销售数据，结果这串数据被分散在好几块物理地址里，还得自己计算偏移、判断跨块，出错概率爆炸。

为了解决这个问题，Atlas 引入了一个今天看起来已是理所当然的概念：**虚拟内存地址（virtual memory）**。

在虚拟内存体系下，每个程序都可以假装自己拥有一块连续的内存，地址从 0 开始排到若干上限。程序只和这套“虚拟地址”打交道。不管真实物理内存多破碎、多复杂，全由操作系统配合硬件（地址转换单元）在背后搞定映射。

对前面那个被拆成两块的程序 A 来说：

* 在物理内存中，它占的是 0–999 和 3000–3999；
* 在程序 A 看来，它拥有的是连续的 0–1999 虚拟地址。

当 A 访问虚拟地址 500，硬件会把它映射到物理地址 500；当访问虚拟地址 1500，映射到物理地址 3500。这个转换过程对程序是完全透明的。

更妙的是，这种机制顺带带来了一个极其重要的特性：**内存保护（memory protection）**。操作系统可以为每个进程设置“只允许访问自己那块虚拟地址空间”，如果某个程序因为 bug 或恶意行为试图写入它不该碰的地址，硬件就会触发异常，把它拦下来。这样，一个程序最多把自己玩坏，而不会轻易把整个系统和其他程序拖下水。

Atlas 是最早在硬件和操作系统层面同时实现虚拟内存和内存保护的机器之一，对后来的所有主流操作系统影响深远。

---

到了 20 世纪 70 年代，计算机继续变快、变便宜。大学、研究所乃至部分公司都会买一台或几台大型机供多人使用。问题也随之升级：**不光要同时跑多个程序，还要同时服务多个用户**。

这一代常见的画面是：机房里有一台冰箱大小的主机，外面连着几十个“终端”（terminal）——每个终端就是一个键盘加一块简单屏幕，自己几乎没有算力，全部依赖后面的那台大机器。像 DEC 的 PDP-10、IBM 的大型机、还有贝尔实验室内部的 PDP-7/PDP-11，都是这样使用的。

要让几十个用户同时敲命令、跑程序，又不能让某个调皮鬼把机器算爆，占光所有资源，人们设计出了**分时系统（time-sharing）**。所谓分时，就是把机器的处理器时间切成一小片一小片（时间片），轮流发给不同用户的进程。因为计算机速度足够快，即便每个用户只占总时间的一小部分，在人眼和键盘的响应尺度下，还是觉得“我的程序在流畅运行”。

在这一时期，一个影响力巨大的操作系统项目是 **Multics**（Multiplexed Information and Computing Service，1969 年问世）。Multics 从一开始就非常重视安全性和多用户隔离：它希望学生不能偷偷用老师账号看试卷，普通用户也不能随意窥探别人文件。为此它设计了复杂的权限模型、分层结构和错误恢复机制，结果就是：**强大，但笨重**。仅操作系统本身，就要占用那时惊人的内存容量，往往需要牺牲整机相当大一部分资源来养这套系统。

贝尔实验室的 Dennis Ritchie 回忆说，Multics 在商业上不太成功，一个重要原因就是“工程过度”：功能太多，太复杂。

---

有趣的是，这种“过度”反而催生了另一套传奇系统：**Unix**。

Multics 项目中两位开发者 Ken Thompson 和 Dennis Ritchie 在退出项目后，决定做一个更小巧、更优雅的系统。他们在一台配置远不如大型机的 PDP-7 上，写出了最初版本的 Unix。Unix 的核心理念是：把操作系统清晰拆成两部分——

* 一部分是作为“内核”（kernel）的核心：进程管理、内存管理、I/O 等最基础的能力；
* 另一部分则是大量实用工具和库：编译器、文本处理工具、各种小程序，运行在内核之上，但不属于内核本身。

为了保持内核简洁，他们刻意不在内核里塞太多“复杂的错误恢复逻辑”。Tom Van Vleck 回忆说，他在 Multics 里写的大量代码是给各种错误做恢复处理，而 Dennis 的态度是：在 Unix 里，大部分这类情况就“别处理了”。如果出大事，干脆调用一个叫 `panic` 的例程，让系统打印“panic”，然后停机，等管理员在走廊里喊一声“重启一下”。

今天你在 macOS 或 Linux 遇到的“内核崩溃”（kernel panic），就是这个传统的延续。

极简的内核加上灵活的工具生态，让 Unix 非常适合在不同学校、研究机构的硬件上移植与扩展。1971 年左右的早期版本就已经拥有 C 语言编译器、文本处理工具、脚本环境，很快成为 70、80 年代学术界和工业界的主流系统之一；后来许多系统——包括今天的 Linux 和 macOS——都直接或间接继承了 Unix 的理念和接口。

---

与此同时，硬件价格继续跳水，个人终于买得起电脑了。进入 80 年代，**个人计算机（PC）** 和家用电脑成为新主角。与大学机房里的大型机相比，这些电脑简单得多：只有一个用户，通常只接几块磁盘、一个显示器、一个键盘，不需要处理几十个终端同时在线的问题。

因此，它们的操作系统也相对简单。早期的 **CP/M** 是 8 位微机上广泛使用的系统之一，而在 1981 年，IBM 推出 IBM PC 时，从一家名不见经传的小公司微软那里拿到了一个系统——这就是后来风靡一时的 **MS-DOS**。MS-DOS 小到只有约 160 KB，可以装进一张软盘里；它基本不支持真正的多任务，更没有虚拟内存和内存保护，一切运行都靠程序之间“自觉”。

结果就是：只要有一个程序犯规写错了内存，就可能直接把整个系统崩掉。这种事在 80、90 年代的日常体验就是：屏幕卡死、键盘没反应，你只能无奈按下机箱上的重启键。即便后来名声大噪的早期 Windows（例如 Windows 3.x、Windows 95/98），在很长一段时间里也没有像今天这样的强内存保护，才有了家喻户晓的“蓝屏死机”（Blue Screen of Death）。

直到 NT 架构的 Windows（例如 Windows NT、Windows 2000、后来的 XP、7、10 等）逐渐普及，微软才在桌面系统上全面引入更接近 Unix 风格的进程隔离、虚拟内存与权限模型，系统稳定性才真正上了一个台阶。

---

今天，我们手边的电脑和手机上跑的，都是这条漫长历史的继承者：
macOS 的底层是基于 Unix 的 Darwin 内核；Windows 10 继承了 Windows NT 的架构；Linux 则从 1991 年 Linus Torvalds 的兴趣项目成长为支撑互联网基础设施的主力；iOS 和 Android 分别建立在 Darwin / Linux 内核之上，把多任务、虚拟内存、内存保护、安全沙箱这些曾经只在大型机上出现的“高级特性”，塞进了手机这样的小设备里。

这就是为什么你可以一边用浏览器刷视频，一边用编辑器改文档，后台还开着音乐播放器与云同步工具——在你眼里只是“同时开了很多软件”，在系统眼里则是几十个进程在 CPU 上争抢时间片，在内存里划分各自的虚拟地址空间，在 I/O 设备上排队进行读写操作。你很少会考虑“这个程序的数组是放在 0–999 号物理地址，还是 3000–3999”，也不会担心一个小 bug 会把整个系统炸成一片蓝屏——这一切麻烦都被操作系统和硬件在几十年的演化中悄悄吞掉了。

如果把这段历史压缩成一句话，就是：

> 人类从一台一次只能跑一个程序、靠人工搬卡片喂纸的怪兽，一路走到今天随手打开一台手机就能同时运行几十个 App，中间跨越的，是虚拟地址、内存保护、多任务、分时系统、设备驱动、文件系统等一整套操作系统技术的进化。

你现在看到的“图标一双击，软件就打开了”，背后站着的是几十年累积的工程技巧和抽象设计。操作系统，就是这段历史的结晶。
